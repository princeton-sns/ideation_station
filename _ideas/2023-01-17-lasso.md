---
title: Laaso
excerpt: Integrating existing automatic parallelization tools with FaaS capabilities
author: Shai (and Ziyang)
status: new
---

*Laaso* == Loops As A Service 

Integrating existing automatic parallelization tools with Functions as a Service could enable faster computation. We are discussing integrating the two spaces in many ways:

1. Using parallelization tools to speed up FaaS deployment (i.e. speeding up cold starts). Essentially altering the underlying servers running serverless functions.
2. Speeding up lambda functions. Applying parallelization tools to already written functions.
3. **the exciting one** using compilers to parallelize code using Functions.

I think option 3 is the coolest. Why? can make FaaS more "accessible".
Right now FaaS makes sense for use cases that need burst parallelism, but what if someone could use the unlimited resources to just speed up computation easily? 

We want to:
* Build a profiling tool that would tell a programmer whether and how their code would benefit from parallelism using FaaS. This tool could also find the optimal cost breakdown, essentially convincing a programmer that with X functions FaaS would be cheaper and faster than just a standard vm. With ex-camera as an example, imagine a developer runs their video decoder through our profiler which tells them that they should split up functions to run video slices (i.e. how to split up memory usage between functions). 
* Build tools to make FaaS parallelism easier to write: for example, introducing a "FaaS loop"notion (probably in Rust) which will help programmers use FaaS.
* Automatically translate between "regular" code to a FaaS version for parallel code parts.
* Translate a sequentially-written program to Functions including optimal parallelism decisions.

The first bullet is the obvious first project to tackle. Essentially we want to see for what workloads that may be obviously parallel FaaS would be the obvious choice for speeding up parallel computation beyond the number of cores on a single machine.
